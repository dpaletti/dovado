"""
This type stub file was generated by pyright.
"""

"""
Created on Mon Aug 04 08:00:16 2014

Author: Josef Perktold
License: BSD-3

"""
descriptions = { 'HC0': 'Standard Errors are heteroscedasticity robust (HC0)','HC1': 'Standard Errors are heteroscedasticity robust (HC1)','HC2': 'Standard Errors are heteroscedasticity robust (HC2)','HC3': 'Standard Errors are heteroscedasticity robust (HC3)','HAC': 'Standard Errors are heteroscedasticity and autocorrelation ' 'robust (HAC) using {maxlags} lags and ' '{correction} small sample correction','fixed_scale': 'Standard Errors are based on fixed scale','cluster': 'Standard Errors are robust to cluster correlation (cluster)','HAC-Panel': 'Standard Errors are robust to ' 'cluster correlation (HAC-Panel)','HAC-Groupsum': 'Driscoll and Kraay Standard Errors are robust to ' 'cluster correlation (HAC-Groupsum)','none': 'Covariance matrix not calculated.','approx': 'Covariance matrix calculated using numerical ({approx_type}) ' 'differentiation.','OPG': 'Covariance matrix calculated using the outer product of ' 'gradients ({approx_type}).','OIM': 'Covariance matrix calculated using the observed information ' 'matrix ({approx_type}) described in Harvey (1989).','robust': 'Quasi-maximum likelihood covariance matrix used for ' 'robustness to some misspecifications; calculated using ' 'numerical ({approx_type}) differentiation.','robust-OIM': 'Quasi-maximum likelihood covariance matrix used for ' 'robustness to some misspecifications; calculated using the ' 'observed information matrix ({approx_type}) described in ' 'Harvey (1989).','robust-approx': 'Quasi-maximum likelihood covariance matrix used for ' 'robustness to some misspecifications; calculated using ' 'numerical ({approx_type}) differentiation.' }
def normalize_cov_type(cov_type):
    """
    Normalize the cov_type string to a canonical version

    Parameters
    ----------
    cov_type : str

    Returns
    -------
    normalized_cov_type : str
    """
    ...

def get_robustcov_results(self, cov_type=..., use_t=..., **kwds):
    """create new results instance with robust covariance as default

    Parameters
    ----------
    cov_type : str
        the type of robust sandwich estimator to use. see Notes below
    use_t : bool
        If true, then the t distribution is used for inference.
        If false, then the normal distribution is used.
    kwds : depends on cov_type
        Required or optional arguments for robust covariance calculation.
        see Notes below

    Returns
    -------
    results : results instance
        This method creates a new results instance with the requested
        robust covariance as the default covariance of the parameters.
        Inferential statistics like p-values and hypothesis tests will be
        based on this covariance matrix.

    Notes
    -----
    Warning: Some of the options and defaults in cov_kwds may be changed in a
    future version.

    The covariance keywords provide an option 'scaling_factor' to adjust the
    scaling of the covariance matrix, that is the covariance is multiplied by
    this factor if it is given and is not `None`. This allows the user to
    adjust the scaling of the covariance matrix to match other statistical
    packages.
    For example, `scaling_factor=(nobs - 1.) / (nobs - k_params)` provides a
    correction so that the robust covariance matrices match those of Stata in
    some models like GLM and discrete Models.

    The following covariance types and required or optional arguments are
    currently available:

    - 'HC0', 'HC1', 'HC2', 'HC3' and no keyword arguments:
        heteroscedasticity robust covariance
    - 'HAC' and keywords

        - `maxlag` integer (required) : number of lags to use
        - `kernel` callable or str (optional) : kernel
              currently available kernels are ['bartlett', 'uniform'],
              default is Bartlett
        - `use_correction` bool (optional) : If true, use small sample
              correction

    - 'cluster' and required keyword `groups`, integer group indicator

        - `groups` array_like, integer (required) :
              index of clusters or groups
        - `use_correction` bool (optional) :
              If True the sandwich covariance is calculated with a small
              sample correction.
              If False the the sandwich covariance is calculated without
              small sample correction.
        - `df_correction` bool (optional)
              If True (default), then the degrees of freedom for the
              inferential statistics and hypothesis tests, such as
              pvalues, f_pvalue, conf_int, and t_test and f_test, are
              based on the number of groups minus one instead of the
              total number of observations minus the number of explanatory
              variables. `df_resid` of the results instance is adjusted.
              If False, then `df_resid` of the results instance is not
              adjusted.

    - 'hac-groupsum' Driscoll and Kraay, heteroscedasticity and
        autocorrelation robust standard errors in panel data
        keywords

        - `time` array_like (required) : index of time periods
        - `maxlag` integer (required) : number of lags to use
        - `kernel` callable or str (optional) : kernel
              currently available kernels are ['bartlett', 'uniform'],
              default is Bartlett
        - `use_correction` False or string in ['hac', 'cluster'] (optional) :
              If False the the sandwich covariance is calculated without
              small sample correction.
              If `use_correction = 'cluster'` (default), then the same
              small sample correction as in the case of 'covtype='cluster''
              is used.
        - `df_correction` bool (optional)
              adjustment to df_resid, see cov_type 'cluster' above
              #TODO: we need more options here

    - 'hac-panel' heteroscedasticity and autocorrelation robust standard
        errors in panel data.
        The data needs to be sorted in this case, the time series for
        each panel unit or cluster need to be stacked. The membership to
        a timeseries of an individual or group can be either specified by
        group indicators or by increasing time periods.

        keywords

        - either `groups` or `time` : array_like (required)
          `groups` : indicator for groups
          `time` : index of time periods
        - `maxlag` integer (required) : number of lags to use
        - `kernel` callable or str (optional) : kernel
              currently available kernels are ['bartlett', 'uniform'],
              default is Bartlett
        - `use_correction` False or string in ['hac', 'cluster'] (optional) :
              If False the the sandwich covariance is calculated without
              small sample correction.
        - `df_correction` bool (optional)
              adjustment to df_resid, see cov_type 'cluster' above
              #TODO: we need more options here

    Reminder:
    `use_correction` in "hac-groupsum" and "hac-panel" is not bool,
    needs to be in [False, 'hac', 'cluster']

    TODO: Currently there is no check for extra or misspelled keywords,
    except in the case of cov_type `HCx`
    """
    ...

